name: FeTS challenge 2022 (task 2) Metrics MLCube
description: MLCube for writing metrics for MedPerf
authors:
 - {name: "MLCommons Medical Working Group"}
 - {name: "Maximilian Zenk (DKFZ)"}

platform:
  accelerator_count: 0

singularity:
  image: fets22metrics.sif
  run_args: "-C --writable-tmpfs --net --network=none --nv"

tasks:
  # Metrics MLCubes require only a single task: `evaluate`
  # This tast takes the predictions generated by the model mlcube (as a directory)
  # and the output of the Data Preparation MLCube containing the labels (as a directory)
  # to compute metrics, which are then stored inside the output_path 
  evaluate:
  # Executes a number of metrics specified by the params file
    parameters:
      inputs: {
        predictions: {type: directory, default: predictions},                            # Required. Where to find the predictions. MUST be a folder
        labels: {type: directory, default: labels},                                      # Required. Where to find the labels. MUST be a folder
        parameters_file: parameters.yaml,                     # Required. Helper file to provide additional arguments. Value MUST be parameters.yaml
        # If you need any additional files that should 
        # not be included inside the mlcube image, 
        # add them inside `additional_files` folder
        }
      outputs: {
        output_path: {type: "file", default: "results.yaml"}, # Required. Where to write the metrics results. Value MUST be results.yaml
        log_path: {type: "file", default: "evaluate.log"} # Where to write the evaluation logs.
        }
